{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c86fc550",
   "metadata": {},
   "source": [
    "## Performing Inference of the developed CNN model on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1256cada",
   "metadata": {},
   "source": [
    "#### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab3f86e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf430c94",
   "metadata": {},
   "source": [
    "#### Load the keras model  and preprocess the data like we did with the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fff8b482",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN=load_model('cnnModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7b1eaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = torch.load(r'C:\\Users\\KIT\\OneDrive\\Documents\\MNISTM\\processed\\mnist_m_test.pt')  #import the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f97adee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = testdata  #seperate the features and kabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b168c023",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = tf.cast(x_test, 'float32') #cast the tensor uint8 data into float 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7308f87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = tf.cast(y_test, 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f531d891",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test/255  #Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1cc2e947",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = CNN.predict(x_test)  #predict the digit labels using formulated CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11500c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "pred = np.argmax(pred, axis = 1)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "96099a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 940,   33,    0,    0,    1,    0,    6,    0,    0,    0],\n",
       "       [   0, 1131,    2,    1,    0,    0,    0,    0,    1,    0],\n",
       "       [   0,   28, 1000,    1,    0,    0,    2,    0,    1,    0],\n",
       "       [   1,   34,    8,  954,    0,    7,    4,    0,    2,    0],\n",
       "       [   0,   51,    0,    0,  918,    0,    3,    1,    1,    8],\n",
       "       [   6,   24,    4,    9,    0,  830,   12,    0,    5,    2],\n",
       "       [   1,   21,    0,    0,    0,    0,  935,    0,    1,    0],\n",
       "       [   0,   68,    6,    2,    1,    0,    0,  950,    0,    1],\n",
       "       [   2,   36,    1,    5,    0,    3,    6,    2,  918,    1],\n",
       "       [   2,   40,    0,    5,    5,    2,    0,    7,    4,  944]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,pred) #check the performance of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e89f3026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.96      0.97       980\n",
      "         1.0       0.77      1.00      0.87      1135\n",
      "         2.0       0.98      0.97      0.97      1032\n",
      "         3.0       0.98      0.94      0.96      1010\n",
      "         4.0       0.99      0.93      0.96       982\n",
      "         5.0       0.99      0.93      0.96       892\n",
      "         6.0       0.97      0.98      0.97       958\n",
      "         7.0       0.99      0.92      0.96      1028\n",
      "         8.0       0.98      0.94      0.96       974\n",
      "         9.0       0.99      0.94      0.96      1009\n",
      "\n",
      "    accuracy                           0.95     10000\n",
      "   macro avg       0.96      0.95      0.95     10000\n",
      "weighted avg       0.96      0.95      0.95     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred)) #further evaluate the performance of the model using PRECISION, RECALL, ACCURACY AND F1-SCORE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89666818",
   "metadata": {},
   "source": [
    "# This is it. Average 95% F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfd21b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
